第1章 并发编程的挑战

1.1上下文切换

即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现 这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切 换线程执行。

CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个 任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这 个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

1.1.1 多线程就一定快吗

当并发执行累加操作不超过百万次时，速度会比串行执行累加操作要慢，因为线程的创建和上下文切换都是有开销的。

1.1.2 测试上下文切换次数和时长

- 使用Lmbench3 [1]可以测量上下文切换的时长
- 使用vmstat可以测量上下文切换的次数。

![](https://i.bmp.ovh/imgs/2022/05/23/4888316920f36051.png)

CS（Content Switch）表示上下文切换的次数，从上面的测试结果中我们可以看到，上下文 每1秒切换1000多次

1.1.3 如何减少上下文切换

减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。

- 无锁并发编程

  无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。

- CAS算法

  Java的Atomic包使用CAS算法来更新数据，而不需要加锁。

- 使用最少线程

  避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这 样会造成大量线程都处于等待状态。

- 使用协程、

  在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

1.1.4 减少上下文切换实战

1.2 死锁

1.3 资源限制的挑战

1.4 本章小节

